# Parellel Operating System

Parallel operating systems are a type of computer processing platform that breaks large tasks into smaller pieces that are done at the same time in different places and by different mechanisms.
They are sometimes also described as “multi-core” processors. This type of system is usually very efficient at handling very large files and complex numerical codes. It’s most commonly seen in research settings where central server systems are handling a lot of different jobs at once
It can be useful any time multiple computers are doing similar jobs and connecting to shared infrastructures simultaneously.

A parallel operating system works by dividing sets of calculations into smaller parts and distributing them between the machines on a network. To facilitate communication between the processor cores and memory arrays, routing software has to either share its memory by assigning the same address space to all of the networked computers, or distribute its memory by assigning a different address space to each processing core. Sharing memory allows the operating system to run very quickly, but it is usually not as powerful.
